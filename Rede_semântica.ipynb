{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAIJ4KF6qBugm+IMgVjMhJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanfisicobr/rede_semantica_EC/blob/main/Rede_sem%C3%A2ntica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xLE0acuJ95U9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aebec9d2-2d9d-4617-f3f8-8eed205361ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas\n",
            "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nltk\n",
            "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting python-louvain\n",
            "  Downloading python-louvain-0.16.tar.gz (204 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.6/204.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Collecting networkx\n",
            "  Downloading networkx-3.6-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting numpy>=1.26.0 (from pandas)\n",
            "  Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.8.2 (from pandas)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting click (from nltk)\n",
            "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting joblib (from nltk)\n",
            "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting regex>=2021.8.3 (from nltk)\n",
            "  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm (from nltk)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Downloading fonttools-4.61.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.2/113.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting packaging>=20.0 (from matplotlib)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pillow>=8 (from matplotlib)\n",
            "  Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
            "Collecting pyparsing>=3 (from matplotlib)\n",
            "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.6-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.6/362.6 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.61.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.9/113.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.3.1-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.3/108.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.4/308.4 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: python-louvain\n",
            "  Building wheel for python-louvain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-louvain: filename=python_louvain-0.16-py3-none-any.whl size=9388 sha256=6fe9bdf9033bace05717ab60e706f0ff2b6e4308326a3e0f1af7b3fc610ddb99\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/f1/e3/485b698c520fa0baee1d07897abc7b8d6479b7d199ce96f4af\n",
            "Successfully built python-louvain\n",
            "Installing collected packages: pytz, tzdata, tqdm, six, regex, pyparsing, pillow, packaging, numpy, networkx, kiwisolver, joblib, fonttools, cycler, click, python-louvain, python-dateutil, nltk, contourpy, pandas, matplotlib\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2025.11.3\n",
            "    Uninstalling regex-2025.11.3:\n",
            "      Successfully uninstalled regex-2025.11.3\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.5\n",
            "    Uninstalling pyparsing-3.2.5:\n",
            "      Successfully uninstalled pyparsing-3.2.5\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.6\n",
            "    Uninstalling networkx-3.6:\n",
            "      Successfully uninstalled networkx-3.6\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.4.9\n",
            "    Uninstalling kiwisolver-1.4.9:\n",
            "      Successfully uninstalled kiwisolver-1.4.9\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.5.2\n",
            "    Uninstalling joblib-1.5.2:\n",
            "      Successfully uninstalled joblib-1.5.2\n",
            "  Attempting uninstall: fonttools\n",
            "    Found existing installation: fonttools 4.60.1\n",
            "    Uninstalling fonttools-4.60.1:\n",
            "      Successfully uninstalled fonttools-4.60.1\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.1\n",
            "    Uninstalling click-8.3.1:\n",
            "      Successfully uninstalled click-8.3.1\n",
            "  Attempting uninstall: python-louvain\n",
            "    Found existing installation: python-louvain 0.16\n",
            "    Uninstalling python-louvain-0.16:\n",
            "      Successfully uninstalled python-louvain-0.16\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.9.1\n",
            "    Uninstalling nltk-3.9.1:\n",
            "      Successfully uninstalled nltk-3.9.1\n",
            "  Attempting uninstall: contourpy\n",
            "    Found existing installation: contourpy 1.3.3\n",
            "    Uninstalling contourpy-1.3.3:\n",
            "      Successfully uninstalled contourpy-1.3.3\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "gradio 5.50.0 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed click-8.3.1 contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.0 joblib-1.5.2 kiwisolver-1.4.9 matplotlib-3.10.7 networkx-3.6 nltk-3.9.2 numpy-2.3.5 packaging-25.0 pandas-2.3.3 pillow-12.0.0 pyparsing-3.2.5 python-dateutil-2.9.0.post0 python-louvain-0.16 pytz-2025.2 regex-2025.11.3 six-1.17.0 tqdm-4.67.1 tzdata-2025.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "community",
                  "cycler",
                  "dateutil",
                  "kiwisolver",
                  "matplotlib",
                  "mpl_toolkits",
                  "networkx",
                  "numpy",
                  "packaging",
                  "pandas",
                  "pyparsing",
                  "pytz",
                  "six"
                ]
              },
              "id": "e2b36d96d5f44d8cacf556f082d844a3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install pandas nltk python-louvain matplotlib networkx --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import re\n",
        "from itertools import combinations\n",
        "import community as community_louvain\n",
        "import matplotlib.pyplot as plt\n",
        "import unicodedata\n",
        "import numpy as np\n",
        "\n",
        "# --- Funções de Processamento de Texto  ---\n",
        "def _eliminar_tildes(texto):\n",
        "    nfkd_form = unicodedata.normalize('NFD', texto)\n",
        "    return \"\".join([c for c in nfkd_form if unicodedata.category(c) != 'Mn'])\n",
        "\n",
        "def preprocess_text(text, custom_stopwords=None):\n",
        "    mapa_normalizacao = {\n",
        "        'pesquisas': 'pesquisa',\n",
        "    }\n",
        "    stop_words = set(['de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos',\n",
        "                      'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo', 'pela',\n",
        "                      'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'nas', 'quais', 'sobre'])\n",
        "    if custom_stopwords:\n",
        "        stop_words.update(custom_stopwords)\n",
        "    text = text.lower()\n",
        "    text = _eliminar_tildes(text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    tokens = text.split()\n",
        "    normalized_tokens = [mapa_normalizacao.get(token, token) for token in tokens]\n",
        "    filtered_tokens = [word for word in normalized_tokens if word not in stop_words and len(word) > 2]\n",
        "    return filtered_tokens\n",
        "\n",
        "def create_cooccurrence_matrix_from_file(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as file:\n",
        "        content = file.read()\n",
        "    documents_raw = content.split('###')\n",
        "    documents_raw = [doc.strip() for doc in documents_raw if doc.strip()]\n",
        "    custom_stopwords = ['educacional', 'formacao']\n",
        "    processed_docs = [preprocess_text(doc, custom_stopwords) for doc in documents_raw]\n",
        "    vocabulary = sorted(list(set(term for doc in processed_docs for term in doc)))\n",
        "    M = pd.DataFrame(0, index=vocabulary, columns=vocabulary)\n",
        "    for doc in processed_docs:\n",
        "        unique_terms_in_doc = sorted(list(set(doc)))\n",
        "        for term in unique_terms_in_doc:\n",
        "            M.loc[term, term] += 1\n",
        "        for term1, term2 in combinations(unique_terms_in_doc, 2):\n",
        "            M.loc[term1, term2] += 1\n",
        "            M.loc[term2, term1] += 1\n",
        "    return M\n",
        "\n",
        "def calcular_e_associar_metricas(G, M):\n",
        "    try:\n",
        "        partition = community_louvain.best_partition(G, weight='weight')\n",
        "    except ValueError:\n",
        "        partition = {n: 0 for n in G.nodes()} # Fallback se o grafo estiver vazio\n",
        "\n",
        "    pagerank = nx.pagerank(G, weight='weight')\n",
        "    occurrences = {term: M.loc[term, term] for term in G.nodes()}\n",
        "    clusters_ajustados = {node: cluster_id + 1 for node, cluster_id in partition.items()}\n",
        "    nx.set_node_attributes(G, clusters_ajustados, 'cluster')\n",
        "    nx.set_node_attributes(G, pagerank, 'pagerank')\n",
        "    nx.set_node_attributes(G, occurrences, 'occurrences')\n",
        "    print(\"Métricas (Cluster, PageRank, Ocorrencias) calculadas e associadas.\")\n",
        "    return G\n",
        "\n",
        "def filtrar_rede(G, top_n, min_edge_weight_for_viz):\n",
        "    if G.number_of_nodes() <= top_n:\n",
        "        top_nodes = list(G.nodes())\n",
        "    else:\n",
        "        pagerank_dict = nx.get_node_attributes(G, 'pagerank')\n",
        "        sorted_nodes = sorted(pagerank_dict, key=pagerank_dict.get, reverse=True)\n",
        "        top_nodes = sorted_nodes[:top_n]\n",
        "    G_sub = G.subgraph(top_nodes).copy()\n",
        "    G_final = nx.Graph()\n",
        "    G_final.add_nodes_from(G_sub.nodes(data=True))\n",
        "    for u, v, data in G_sub.edges(data=True):\n",
        "        if data['weight'] >= min_edge_weight_for_viz:\n",
        "            G_final.add_edge(u, v, weight=data['weight'])\n",
        "    G_final.remove_nodes_from(list(nx.isolates(G_final)))\n",
        "    print(f\"Rede final: {G_final.number_of_nodes()} nós, {G_final.number_of_edges()} arestas.\")\n",
        "    return G_final\n",
        "\n",
        "\n",
        "#  FUNÇÃO DE VISUALIZAÇÃO\n",
        "\n",
        "def visualizar_rede_estilizada(G, title, output_filename):\n",
        "    if G.number_of_nodes() == 0:\n",
        "        print(\"A rede está vazia.\")\n",
        "        return\n",
        "    G.remove_edges_from(nx.selfloop_edges(G))\n",
        "\n",
        "    plt.figure(figsize=(20, 12), facecolor='white')\n",
        "    ax = plt.gca()\n",
        "\n",
        "    # --- Layout Centralizado ---\n",
        "    pagerank_dict = nx.get_node_attributes(G, 'pagerank')\n",
        "    central_node = max(pagerank_dict, key=pagerank_dict.get)\n",
        "    pos = nx.spring_layout(G, k=0.5, iterations=10, seed=42)\n",
        "    pos[central_node] = np.array([0, 0])\n",
        "\n",
        "\n",
        "    for node, coords in pos.items():\n",
        "        if node != central_node:\n",
        "            norm = np.linalg.norm(coords)\n",
        "            if norm == 0: norm = 1\n",
        "            pos[node] = coords + (coords / norm) * 0.3 # Afasta 30%\n",
        "\n",
        "\n",
        "    cluster_values = [data.get('cluster', 0) for _, data in G.nodes(data=True)]\n",
        "    cmap = plt.cm.get_cmap('Set1')\n",
        "\n",
        "\n",
        "    pagerank_values = [data.get('pagerank', 0) for _, data in G.nodes(data=True)]\n",
        "    min_size = 2000\n",
        "    max_size = 20000\n",
        "\n",
        "    node_sizes = []\n",
        "    if pagerank_values:\n",
        "        min_pr, max_pr = min(pagerank_values), max(pagerank_values)\n",
        "        for p in pagerank_values:\n",
        "            size = min_size + ((p - min_pr) / (max_pr - min_pr + 1e-9)) * (max_size - min_size)\n",
        "            node_sizes.append(size)\n",
        "\n",
        "\n",
        "    node_list = list(G.nodes())\n",
        "    central_idx = node_list.index(central_node)\n",
        "    node_sizes[central_idx] = 25000\n",
        "\n",
        "    # --- Desenhar o \"Halo\" ---\n",
        "\n",
        "    nx.draw_networkx_nodes(\n",
        "        G, pos,\n",
        "        node_color=cluster_values, cmap=cmap,\n",
        "        node_size=[s * 1.2 for s in node_sizes],\n",
        "        alpha=0.2,\n",
        "        linewidths=0\n",
        "    )\n",
        "\n",
        "    # Desenha o núcleo dos nós\n",
        "    nodes = nx.draw_networkx_nodes(\n",
        "        G, pos,\n",
        "        node_color=cluster_values, cmap=cmap,\n",
        "        node_size=node_sizes,\n",
        "        alpha=0.7,\n",
        "        edgecolors='white', linewidths=2\n",
        "    )\n",
        "\n",
        "    # ---  Arestas Curvas ---\n",
        "    edge_weights = [data['weight'] for u, v, data in G.edges(data=True)]\n",
        "    if edge_weights:\n",
        "        max_w = max(edge_weights)\n",
        "        widths = [1 + (w / max_w * 4) for w in edge_weights]\n",
        "    else:\n",
        "        widths = 1\n",
        "\n",
        "    nx.draw_networkx_edges(\n",
        "        G, pos,\n",
        "        alpha=0.4,\n",
        "        width=widths,\n",
        "        edge_color='#999999',\n",
        "        connectionstyle=\"arc3,rad=0.3\"\n",
        "    )\n",
        "\n",
        "\n",
        "    labels = {}\n",
        "    for node, data in G.nodes(data=True):\n",
        "        if node == central_node:\n",
        "            labels[node] = node.upper() # Caixa alta para o central\n",
        "        else:\n",
        "            # Quebra linha se for muito longo\n",
        "            lbl = node\n",
        "            if len(lbl) > 10 and ' ' in lbl:\n",
        "                lbl = lbl.replace(' ', '\\n', 1)\n",
        "            labels[node] = lbl\n",
        "\n",
        "    nx.draw_networkx_labels(\n",
        "        G, pos,\n",
        "        labels={central_node: labels[central_node]},\n",
        "        font_size=35,\n",
        "        font_weight='bold',\n",
        "        font_family='sans-serif',\n",
        "        font_color='black'\n",
        "    )\n",
        "\n",
        "    # Desenha rótulos periféricos\n",
        "    other_labels = {n: l for n, l in labels.items() if n != central_node}\n",
        "\n",
        "    pos_labels = {n: (x, y - 0.08) for n, (x, y) in pos.items()}\n",
        "\n",
        "    size_map = dict(zip(G.nodes(), node_sizes))\n",
        "\n",
        "    for node, label in other_labels.items():\n",
        "\n",
        "        n_size = size_map.get(node, 2000)\n",
        "\n",
        "        font_calc = 10 + (n_size / 1200)\n",
        "        final_font_size = min(max(font_calc, 10), 24) # Limita entre 10 e 24\n",
        "\n",
        "        nx.draw_networkx_labels(\n",
        "            G, pos,\n",
        "            labels={node: label},\n",
        "            font_size=final_font_size,\n",
        "            font_weight='medium',\n",
        "            font_color='#555555',\n",
        "            # O bbox ajuda na leitura, especialmente se a fonte variar muito\n",
        "            bbox=dict(facecolor='white', alpha=0.6, edgecolor='none', pad=0.5)\n",
        "        )\n",
        "\n",
        "    plt.title(title, size=18, color='#333333', loc='left')\n",
        "    plt.axis('off') # Remove eixos\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_filename, dpi=600, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"\\nGráfico '{output_filename}' guardado com estilo curvo e centralizado!\")\n",
        "\n",
        "## ----------------------------------------------------------------\n",
        "## EXECUÇÃO\n",
        "## ----------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # --- Configurações ---\n",
        "    FILE_PATH = 'OBJETO_DE_COMPARAÇÃO.txt'\n",
        "    TOP_N_NODES = 25 # Reduzi um pouco para ficar mais limpo como na imagem\n",
        "    MIN_EDGE_WEIGHT_VIZ = 1\n",
        "    GRAFICO_TITULO = \"\"\n",
        "    GRAFICO_OUTPUT_FILE = \"rede_estilo_imagem.png\"\n",
        "    MAPEO_ETIQUETAS_FILE = 'mapeo_terminos.csv'\n",
        "\n",
        "\n",
        "    # --- 1. Flujo de trabajo estándar (hasta el filtrado) ---\n",
        "    print(\"Iniciando análisis...\")\n",
        "    matriz_M = create_cooccurrence_matrix_from_file(FILE_PATH)\n",
        "    grafo_base = nx.from_pandas_adjacency(matriz_M)\n",
        "    grafo_com_metricas = calcular_e_associar_metricas(grafo_base, matriz_M)\n",
        "    grafo_final = filtrar_rede(grafo_com_metricas, top_n=TOP_N_NODES, min_edge_weight_for_viz=MIN_EDGE_WEIGHT_VIZ)\n",
        "\n",
        "    # --- 2. Exportar nodos para corrección de tildes ---\n",
        "\n",
        "    # Obtener la lista de nodos del grafo final\n",
        "    nodos_sin_tildes = list(grafo_final.nodes())\n",
        "\n",
        "    # Crear un DataFrame de Pandas: original -> corregido\n",
        "    # Inicialmente, ambas columnas son iguales.\n",
        "    df_mapa = pd.DataFrame({\n",
        "        'original_sin_tilde': nodos_sin_tildes,\n",
        "        'corregido_con_tilde': nodos_sin_tildes\n",
        "    })\n",
        "\n",
        "    # Guardar en un archivo CSV\n",
        "    df_mapa.to_csv(MAPEO_ETIQUETAS_FILE, index=False, encoding='utf-8-sig')\n",
        "\n",
        "    # --- 3.  Pausa para la edición manual ---\n",
        "    print(\"-\" * 70)\n",
        "    print(f\"ARCHIVO CREADO: '{MAPEO_ETIQUETAS_FILE}'\")\n",
        "    print(\"Por favor, abre este archivo CSV (con Excel, Google Sheets, o un editor de texto).\")\n",
        "    print(\"Modifica la columna 'corregido_con_tilde' para añadir las tildes necesarias.\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    # Pausa el script y espera a que el usuario presione Enter\n",
        "    input(\">>> PRESIONA ENTER para continuar después de guardar tus cambios... \")\n",
        "\n",
        "    # --- 4. Importar mapa corregido y re-etiquetar ---\n",
        "    print(\"Leyendo el archivo de etiquetas corregido...\")\n",
        "\n",
        "    # Leer el archivo que acabas de editar\n",
        "    try:\n",
        "        df_mapa_editado = pd.read_csv(MAPEO_ETIQUETAS_FILE, encoding='utf-8-sig')\n",
        "    except Exception as e:\n",
        "        print(f\"Error leyendo el archivo {MAPEO_ETIQUETAS_FILE}: {e}\")\n",
        "        print(\"Asegúrate de que el archivo esté guardado correctamente.\")\n",
        "        exit()\n",
        "\n",
        "    # Crear el diccionario de mapeo\n",
        "    mapa_de_etiquetas = pd.Series(\n",
        "        df_mapa_editado.corregido_con_tilde.values,\n",
        "        index=df_mapa_editado.original_sin_tilde\n",
        "    ).to_dict()\n",
        "\n",
        "    # Aplicar el re-etiquetado al grafo\n",
        "    grafo_etiquetado = nx.relabel_nodes(grafo_final, mapa_de_etiquetas, copy=True)\n",
        "\n",
        "    print(\"Nodos re-etiquetados con éxito.\")\n",
        "\n",
        "    # --- 5. Ejecución del flujo de trabajo (Visualización) ---\n",
        "    visualizar_rede_estilizada(\n",
        "        grafo_etiquetado,\n",
        "        GRAFICO_TITULO,\n",
        "        GRAFICO_OUTPUT_FILE\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tTGONjS9XrT",
        "outputId": "da05ae60-7b54-427f-9bd3-5164ddfa3260"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando análisis...\n",
            "Métricas (Cluster, PageRank, Ocorrencias) calculadas e associadas.\n",
            "Rede final: 25 nós, 59 arestas.\n",
            "----------------------------------------------------------------------\n",
            "ARCHIVO CREADO: 'mapeo_terminos.csv'\n",
            "Por favor, abre este archivo CSV (con Excel, Google Sheets, o un editor de texto).\n",
            "Modifica la columna 'corregido_con_tilde' para añadir las tildes necesarias.\n",
            "----------------------------------------------------------------------\n",
            ">>> PRESIONA ENTER para continuar después de guardar tus cambios... \n",
            "Leyendo el archivo de etiquetas corregido...\n",
            "Nodos re-etiquetados con éxito.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3947474870.py:110: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
            "  cmap = plt.cm.get_cmap('Set1')\n",
            "/tmp/ipython-input-3947474870.py:158: UserWarning: \n",
            "\n",
            "The connectionstyle keyword argument is not applicable when drawing edges\n",
            "with LineCollection.\n",
            "\n",
            "To make this warning go away, either specify `arrows=True` to\n",
            "force FancyArrowPatches or use the default values.\n",
            "Note that using FancyArrowPatches may be slow for large graphs.\n",
            "\n",
            "  nx.draw_networkx_edges(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gráfico 'rede_estilo_imagem.png' guardado com estilo curvo e centralizado!\n"
          ]
        }
      ]
    }
  ]
}